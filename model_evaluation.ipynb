{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3851d4-b360-49e3-a76b-b4542d9da7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e71309d-83dd-40da-8b24-54124da58d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2      3       4       5        6        7        8   \\\n",
       "0      842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "1      842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2    84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3    84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..        ... ..    ...    ...     ...     ...      ...      ...      ...   \n",
       "564    926424  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565    926682  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566    926954  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567    927241  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568     92751  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "          9   ...      22     23      24      25       26       27      28  \\\n",
       "0    0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                   'machine-learning-databases'\n",
    "                   '/breast-cancer-wisconsin/wdbc.data',\n",
    "                   header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a004172a-df5c-46e6-828a-533c8ce33f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "x=df.loc[:,2].values\n",
    "y=df.loc[:,1].values\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13278b1a-c163-4371-9e92-c06dd89ded9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['M','B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b46b1e-9345-4406-b9df-5731395863d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=\\\n",
    "    train_test_split(x,y,test_size=0.2,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f289741e-63af-4f93-a6e3-5e97e84b9256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.99 , 20.57 , 19.69 , 11.42 , 20.29 , 12.45 , 18.25 , 13.71 ,\n",
       "       13.   , 12.46 , 16.02 , 15.78 , 19.17 , 15.85 , 13.73 , 14.54 ,\n",
       "       14.68 , 16.13 , 19.81 , 13.54 , 13.08 ,  9.504, 15.34 , 21.16 ,\n",
       "       16.65 , 17.14 , 14.58 , 18.61 , 15.3  , 17.57 , 18.63 , 11.84 ,\n",
       "       17.02 , 19.27 , 16.13 , 16.74 , 14.25 , 13.03 , 14.99 , 13.48 ,\n",
       "       13.44 , 10.95 , 19.07 , 13.28 , 13.17 , 18.65 ,  8.196, 13.17 ,\n",
       "       12.05 , 13.49 , 11.76 , 13.64 , 11.94 , 18.22 , 15.1  , 11.52 ,\n",
       "       19.21 , 14.71 , 13.05 ,  8.618, 10.17 ,  8.598, 14.25 ,  9.173,\n",
       "       12.68 , 14.78 ,  9.465, 11.31 ,  9.029, 12.78 , 18.94 ,  8.888,\n",
       "       17.2  , 13.8  , 12.31 , 16.07 , 13.53 , 18.05 , 20.18 , 12.86 ,\n",
       "       11.45 , 13.34 , 25.22 , 19.1  , 12.   , 18.46 , 14.48 , 19.02 ,\n",
       "       12.36 , 14.64 , 14.62 , 15.37 , 13.27 , 13.45 , 15.06 , 20.26 ,\n",
       "       12.18 ,  9.787, 11.6  , 14.42 , 13.61 ,  6.981, 12.18 ,  9.876,\n",
       "       10.49 , 13.11 , 11.64 , 12.36 , 22.27 , 11.34 ,  9.777, 12.63 ,\n",
       "       14.26 , 10.51 ,  8.726, 11.93 ,  8.95 , 14.87 , 15.78 , 17.95 ,\n",
       "       11.41 , 18.66 , 24.25 , 14.5  , 13.37 , 13.85 , 13.61 , 19.   ,\n",
       "       15.1  , 19.79 , 12.19 , 15.46 , 16.16 , 15.71 , 18.45 , 12.77 ,\n",
       "       11.71 , 11.43 , 14.95 , 11.28 ,  9.738, 16.11 , 11.43 , 12.9  ,\n",
       "       10.75 , 11.9  , 11.8  , 14.95 , 14.44 , 13.74 , 13.   ,  8.219,\n",
       "        9.731, 11.15 , 13.15 , 12.25 , 17.68 , 16.84 , 12.06 , 10.9  ,\n",
       "       11.75 , 19.19 , 19.59 , 12.34 , 23.27 , 14.97 , 10.8  , 16.78 ,\n",
       "       17.47 , 14.97 , 12.32 , 13.43 , 15.46 , 11.08 , 10.66 ,  8.671,\n",
       "        9.904, 16.46 , 13.01 , 12.81 , 27.22 , 21.09 , 15.7  , 11.41 ,\n",
       "       15.28 , 10.08 , 18.31 , 11.71 , 11.81 , 12.3  , 14.22 , 12.77 ,\n",
       "        9.72 , 12.34 , 14.86 , 12.91 , 13.77 , 18.08 , 19.18 , 14.45 ,\n",
       "       12.23 , 17.54 , 23.29 , 13.81 , 12.47 , 15.12 ,  9.876, 17.01 ,\n",
       "       13.11 , 15.27 , 20.58 , 11.84 , 28.11 , 17.42 , 14.19 , 13.86 ,\n",
       "       11.89 , 10.2  , 19.8  , 19.53 , 13.65 , 13.56 , 10.18 , 15.75 ,\n",
       "       13.27 , 14.34 , 10.44 , 15.   , 12.62 , 12.83 , 17.05 , 11.32 ,\n",
       "       11.22 , 20.51 ,  9.567, 14.03 , 23.21 , 20.48 , 14.22 , 17.46 ,\n",
       "       13.64 , 12.42 , 11.3  , 13.75 , 19.4  , 10.48 , 13.2  , 12.89 ,\n",
       "       10.65 , 11.52 , 20.94 , 11.5  , 19.73 , 17.3  , 19.45 , 13.96 ,\n",
       "       19.55 , 15.32 , 15.66 , 15.53 , 20.31 , 17.35 , 17.29 , 15.61 ,\n",
       "       17.19 , 20.73 , 10.6  , 13.59 , 12.87 , 10.71 , 14.29 , 11.29 ,\n",
       "       21.75 ,  9.742, 17.93 , 11.89 , 11.33 , 18.81 , 13.59 , 13.85 ,\n",
       "       19.16 , 11.74 , 19.4  , 16.24 , 12.89 , 12.58 , 11.94 , 12.89 ,\n",
       "       11.26 , 11.37 , 14.41 , 14.96 , 12.95 , 11.85 , 12.72 , 13.77 ,\n",
       "       10.91 , 11.76 , 14.26 , 10.51 , 19.53 , 12.46 , 20.09 , 10.49 ,\n",
       "       11.46 , 11.6  , 13.2  ,  9.   , 13.5  , 13.05 , 11.7  , 14.61 ,\n",
       "       12.76 , 11.54 ,  8.597, 12.49 , 12.18 , 18.22 ,  9.042, 12.43 ,\n",
       "       10.25 , 20.16 , 12.86 , 20.34 , 12.2  , 12.67 , 14.11 , 12.03 ,\n",
       "       16.27 , 16.26 , 16.03 , 12.98 , 11.22 , 11.25 , 12.3  , 17.06 ,\n",
       "       12.99 , 18.77 , 10.05 , 23.51 , 14.42 ,  9.606, 11.06 , 19.68 ,\n",
       "       11.71 , 10.26 , 12.06 , 14.76 , 11.47 , 11.95 , 11.66 , 15.75 ,\n",
       "       25.73 , 15.08 , 11.14 , 12.56 , 13.05 , 13.87 ,  8.878,  9.436,\n",
       "       12.54 , 13.3  , 12.76 , 16.5  , 13.4  , 20.44 , 20.2  , 12.21 ,\n",
       "       21.71 , 22.01 , 16.35 , 15.19 , 21.37 , 20.64 , 13.69 , 16.17 ,\n",
       "       10.57 , 13.46 , 13.66 , 11.08 , 11.27 , 11.04 , 12.05 , 12.39 ,\n",
       "       13.28 , 14.6  , 12.21 , 13.88 , 11.27 , 19.55 , 10.26 ,  8.734,\n",
       "       15.49 , 21.61 , 12.1  , 14.06 , 13.51 , 12.8  , 11.06 , 11.8  ,\n",
       "       17.91 , 11.93 , 12.96 , 12.94 , 12.34 , 10.94 , 16.14 , 12.85 ,\n",
       "       17.99 , 12.27 , 11.36 , 11.04 ,  9.397, 14.99 , 15.13 , 11.89 ,\n",
       "        9.405, 15.5  , 12.7  , 11.16 , 11.57 , 14.69 , 11.61 , 13.66 ,\n",
       "        9.742, 10.03 , 10.48 , 10.8  , 11.13 , 12.72 , 14.9  , 12.4  ,\n",
       "       20.18 , 18.82 , 14.86 , 13.98 , 12.87 , 14.04 , 13.85 , 14.02 ,\n",
       "       10.97 , 17.27 , 13.78 , 10.57 , 18.03 , 11.99 , 17.75 , 14.8  ,\n",
       "       14.53 , 21.1  , 11.87 , 19.59 , 12.   , 14.53 , 12.62 , 13.38 ,\n",
       "       11.63 , 13.21 , 13.   ,  9.755, 17.08 , 27.42 , 14.4  , 11.6  ,\n",
       "       13.17 , 13.24 , 13.14 ,  9.668, 17.6  , 11.62 ,  9.667, 12.04 ,\n",
       "       14.92 , 12.27 , 10.88 , 12.83 , 14.2  , 13.9  , 11.49 , 16.25 ,\n",
       "       12.16 , 13.9  , 13.47 , 13.7  , 15.73 , 12.45 , 14.64 , 19.44 ,\n",
       "       11.68 , 16.69 , 12.25 , 17.85 , 18.01 , 12.46 , 13.16 , 14.87 ,\n",
       "       12.65 , 12.47 , 18.49 , 20.59 , 15.04 , 13.82 , 12.54 , 23.09 ,\n",
       "        9.268,  9.676, 12.22 , 11.06 , 16.3  , 15.46 , 11.74 , 14.81 ,\n",
       "       13.4  , 14.58 , 15.05 , 11.34 , 18.31 , 19.89 , 12.88 , 12.75 ,\n",
       "        9.295, 24.63 , 11.26 , 13.71 ,  9.847,  8.571, 13.46 , 12.34 ,\n",
       "       13.94 , 12.07 , 11.75 , 11.67 , 13.68 , 20.47 , 10.96 , 20.55 ,\n",
       "       14.27 , 11.69 ,  7.729,  7.691, 11.54 , 14.47 , 14.74 , 13.21 ,\n",
       "       13.87 , 13.62 , 10.32 , 10.26 ,  9.683, 10.82 , 10.86 , 11.13 ,\n",
       "       12.77 ,  9.333, 12.88 , 10.29 , 10.16 ,  9.423, 14.59 , 11.51 ,\n",
       "       14.05 , 11.2  , 15.22 , 20.92 , 21.56 , 20.13 , 16.6  , 20.6  ,\n",
       "        7.76 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8135f982-9334-44c9-bfa7-0bf51972c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eac01dd-bc45-4331-9cfb-6212b335291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming x_train, y_train, x_test, y_test are already defined\n",
    "# If x_train and x_test are 1D arrays, reshape them to 2D arrays\n",
    "if len(x_train.shape) == 1:\n",
    "    x_train = x_train.reshape(-1, 1)  # Reshape to [n_samples, 1]\n",
    "if len(x_test.shape) == 1:\n",
    "    x_test = x_test.reshape(-1, 1)  # Reshape to [n_samples, 1]\n",
    "\n",
    "# Create and fit the pipeline\n",
    "# Changed n_components=2 to n_components=1 since data only has 1 feature\n",
    "# Or remove PCA entirely if dimensionality reduction isn't needed for 1D data\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                      LogisticRegression())\n",
    "pipe_lr.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "y_pred = pipe_lr.predict(x_test)\n",
    "test_acc = pipe_lr.score(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea082a-4175-4c80-a448-d84580a4b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add model_evaluation.ipynb\n",
    "!git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project2]",
   "language": "python",
   "name": "conda-env-project2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
